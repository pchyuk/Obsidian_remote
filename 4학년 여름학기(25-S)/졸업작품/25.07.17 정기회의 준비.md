## 1. Gemini 1.5가 생성한 데이터 셋으로 학습 + GPT2 데이터 셋으로 테스트
### 데이터셋 구성
#### 인간 데이터셋: 기존과 동일
- train: 25만 개
- test: 5천 개
- valid: 5천 개
#### AI 데이터셋: Gemini 1.5 생성 100%
- train: 25만 개
- test: 5천 개
- valid: 5천 개

---
### 학습 결과

![[confusion_matrix.png]]

![[Pasted image 20250716201027.png]]

![[Pasted image 20250716201050.png]]

![[Pasted image 20250716201130.png]]

- 에폭 돌 때 까지만 하더라도 결과가 99.9%로 과하게 잘 나오길래 당연히 과적합이겠거니 했는데, 
- 테스트를 돌려 보니 정확도가 93% 정도로 꽤 의미있는 결과가 나옴... 뭐지
- 일단 이 모델 파일을 따로 저장해두긴 했음

---
## 2. Gemini 1.5가 생성한 데이터 셋으로 학습 + Gemini 1.5 데이터 셋으로 테스트
### 테스트 결과

![[confusion_matrix 1.png]]

![[Pasted image 20250716202310.png]]

- 음 개판입니다. 이건 또 뭐지

---
## 3. 뭐가 문제일까?
- 지금 Gemini 1.5로 학습시키기 이전에, GPT4가 생성한 데이터셋으로도 학습 시켜봤을 때도 비슷한 결과가 나왔음.
	- 저번 회의때 봤던 그것 (정확도가 99퍼 넘게 나오다가 갑자기 60퍼센트로 훅 떨어짐. 결과도 당연히 개판이었음)
- 모든 조건이 동일한 상황에서, 데이터 셋만 바꿨는데 이렇게 된다고?
- Hugging Face 데이터 셋이 좀 이상한가...?

---
## 4. 그래서 어케 할 거임?
### 당장 할 수 있는 것
- 기존에 있었던 데이터 셋(gpt2 xl)으로 다시 학습시켜보기 - 진행중
	- 만약 이랬는데도 똑같은 문제가 생긴다면, 그건 모델에 문제가 생긴 게 아닐까
- HF 말고 Kaggle에서 받은 데이터 셋으로 다시 학습시켜보기
	- 이미 받아 놓은 데이터셋이 있음.
- 위 두개가 잘 동작한다면, HF 데이터 셋도 다시 학습시켜보기

### 앞으로 할 일
- 현재 사용하고 있는 RoBERTa 모델 말고, 다른 모델도 한번 알아보기
- 데이터 셋을 "직접" 만들어 보기
	- GPT와 Gemini에게, 너가 