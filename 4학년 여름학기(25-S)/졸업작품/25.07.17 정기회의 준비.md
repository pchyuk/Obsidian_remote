## 1. Gemini 1.5가 생성한 데이터 셋으로 학습 + GPT2 데이터 셋으로 테스트
### 데이터셋 구성
#### 인간 데이터셋: 기존과 동일
- train: 25만 개
- test: 5천 개
- valid: 5천 개
#### AI 데이터셋: Gemini 1.5 생성 100%
- train: 25만 개
- test: 5천 개
- valid: 5천 개

---
### 학습 결과

![[confusion_matrix.png]]

![[Pasted image 20250716201027.png]]

![[Pasted image 20250716201050.png]]

![[Pasted image 20250716201130.png]]

- 에폭 돌 때 까지만 하더라도 결과가 99.9%로 과하게 잘 나오길래 당연히 과적합이겠거니 했는데, 
- 테스트를 돌려 보니 정확도가 93% 정도로 꽤 의미있는 결과가 나옴... 뭐지

---
## 2. Gemini 1.5가 생성한 데이터 셋으로 학습 + Gemini 1.5 데이터 셋으로 테스트
### 테스트 결과

![[confusion_matrix 1.png]]

![[Pasted image 20250716202310.png]]

- 음 개판입니다. 이건 또 뭐지

---
## 3. 뭐가 문제일까?
- 지금 Gemini 1.5로 학습시키기 이전에, GPT4가 생성한 데이터셋으로도 학습 시켜봤는데 비슷한 결과가 나왔음
	- 저번 회의때 봤던 그것 (정확도가 99퍼 넘게 나오다가 갑자기 60퍼센트로 훅 떨어짐. 결과도 당연히 개판이었음)
- 모든 조건이 동일한 상황에서, 데이터 셋만 바꿨는데 이렇게 된다고?
- Hugging Face 데이터 셋이 좀 이상한가...?

---
## 4. 그래서 어케 할 거임?
